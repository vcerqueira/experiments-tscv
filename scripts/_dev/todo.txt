# todo implement cv approaches
- [x] time-wise holdout
- [x] series-wise holdout
- [x] series-wise repeated holdout
- [x] series-wise k-fold cv
- [x] series-wise repeated k-fold cv
- [x] series-wise bootstrapping
- [x] series-wise repeated bootstrapping
- [x] series-wise monte carlo cv

# todo learning methods
- [x] auto models: configuration selected using the validation set
    - problem is, the specific configuration may vary. so we're estimating the workflow
- [ ] pre-defined pool of models: easier to run

# todo variants
- [ ] standard rolling origin
- [ ] embargo
- [ ] aggregation per fold v per series
- [ ] one shot test v n_windows-based


# todo analysis variants
- [ ] selection v estimation
- [ ] sensitivity to sample size
- [ ] are we estimating the workflow (incl. HPO) or the final model (retrained OR not)?


# todo analysis
- [ ] per dataset: dataset sample size issue
- [ ] per time series: disregarding potential dependencies?? but solves the modelling issue as we could use automodels


## Notes
- focused on neural networks trained for cross-learning
- check if we are using the validation set

